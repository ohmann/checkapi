'''
<Program Name>
  systolic_verification.repy

<Started>
  This version was started on Apr 11, 2011, however it has been an ongoing 
  project since Autumn 2010.

<Author>
  jeffra45@.cs.washington.edu
  Jeff Rasley

<Purpose>
  Does the verification/execution of API calls in the core_model. Also is
  responsible for backtracking and clearing of in memory state.
'''

# List of function names that require an object id.
OBJ_METHOD_CALLS_SET = set(["file_close", "file_readat", "file_writeat",
                            "lock_acquire", "lock_release", "socket_close",
                            "socket_recv", "socket_send",
                            "udpserver_getmessage",
                            "udpserver_close", "tcpserver_close",
                            "tcpserver_getconnection"])

# For compatibility with shims, we must know what the signature of a non-wrapped 
# Repy object looks like.
NAMESPACE_OBJ = "<class 'namespace.NamespaceObjectWrapper'>"


class ActionNode(object):
  def __init__(self, action_num):
    self.action_num = action_num
    self.children = []

  def is_leaf(self):
    if self.action_num != -1:
      return len(self.children) == 0
    else:
      return False

  def __str__(self):
    return self.action_num




def is_model_object(obj):
  if isinstance(obj, (tuple, list)):
    answer = False
    for a in obj:
      answer = answer or is_model_object(a)
    return answer
  
  if CHECKAPI_FOR_SHIMS:
    objtype = ShimSocketWrapper
  else:
    objtype = ModelObject
  return isinstance(obj, objtype) or NAMESPACE_OBJ in str(type(obj))




def create_tree(sigma_list, condition_dict):
  new_sigma_set = set(sigma_list)
  status = _create_children(new_sigma_set, condition_dict, ActionNode(-1))
  return status




def _remove_element(sigma_set, action_num):
  new_sigma_set = set(sigma_set)
  new_sigma_set.discard(action_num)
  return new_sigma_set




# TODO: This could be cleaned up a bit...
def _contained_in(aset, bset):
  # Checks to see if any elements of aset are contained in bset.
  contains = False
  for b_val in bset:
    for a_val in aset:
      if a_val == b_val:
        contains = True
        break
    if contains:
      break
  return contains




def _node_ok(action_num, condition_dict, sigma_set):
  if action_num in condition_dict and _contained_in(condition_dict[action_num], sigma_set):
    return False
  else:
    return True




def _create_children(sigma_set, condition_dict, start_node):
  if len(sigma_set) == 0:
    return True

  for action_num in sigma_set:
    if _node_ok(action_num, condition_dict, sigma_set):
      # Try in model!
      prestate = exec_and_verif_with_model(action_num)
      if prestate != None:
        # Okay in model, keep going!
        new_node = ActionNode(action_num)
        start_node.children.append(new_node)
        new_sigma_set = _remove_element(sigma_set, action_num)
        if not _create_children(new_sigma_set, condition_dict, new_node):
          # A child node failed, revert and continue.
          put_global_state_dict(prestate)
          log('.')
          continue
        else:
          # All children are okay, found a good ordering.
          return True
      else:
        continue
  # Traversed all of simga and could not find a working ordering.
  return False




def _assert_object(fnc_name, impl_ret):
  if fnc_name == "tcpserver_getconnection":
    assert len(impl_ret) == 3
    assert isinstance(impl_ret, tuple)
    assert isinstance(impl_ret[2], str)
  else:
    assert isinstance(impl_ret, str)




def _get_obj_implid(impl_ret):
  if CHECKAPI_FOR_SHIMS:
    impl_obj_id = impl_ret._socket.implid
  else:
    impl_obj_id = impl_ret.implid
  return impl_obj_id




def _get_and_store_obj_mapping(fnc_name, impl_ret, model_ret):
  if fnc_name == "tcpserver_getconnection":
    tuple_ip, tuple_port, tuple_socket = impl_ret
    impl_obj_id = tuple_socket
    assert impl_obj_id is not None
    assert isinstance(impl_obj_id, str)
    assert isinstance(model_ret, tuple)
    assert len(model_ret) == 3
    model_ip, model_port, model_socket = model_ret
    mycontext['translate_ids'][impl_obj_id] = model_socket
    
  else:
    # Direct translation from unique impl object id to the newly generated
    # model object id. This is used to map this object instance to later 
    # instance method calls. 
    #impl_obj_id = _get_obj_implid(impl_ret)
    impl_obj_id = impl_ret
    mycontext['translate_ids'][impl_obj_id] = model_ret




def _verify_model_impl_values(fnc_name, model_ret, impl_ret):
  # Check for conformance failures.
  if fnc_name in OBJ_CREATE_CALLS_DICT:
    
    if impl_ret == model_ret:
      return True

    # TODO: Generalize how these special case return values are verified/compared.
    elif fnc_name == "tcpserver_getconnection":
      if len(model_ret) != 3 or len(impl_ret) != 3:
        # Incorrect length of return value.
        error_str = fnc_name + " should return tuples of length 3."
        mycontext['failure_messages'].append(error_str)
        return False

      # Check to see that each component of the tuple have matching components.
      model_ip, model_port, model_sock = model_ret
      impl_ip, impl_port, impl_sock = impl_ret
      if model_ip != impl_ip:
        error_str = fnc_name + " action did not return correct ips "
        error_str += str(model_ret) + ", " + str(impl_ret) + '\n'
        mycontext['failure_messages'].append(error_str)
        return False

      elif model_port != impl_port:
        error_str = fnc_name + " action did not return correct ports. "
        error_str += str(model_ret) + ", " + str(impl_ret) + '\n'
        mycontext['failure_messages'].append(error_str)
        return False

      elif not isinstance(model_sock, str) or not isinstance(impl_sock, str):
        error_str = fnc_name + " action did not return correct socket objects. "
        error_str += str(model_ret) + ", " + str(impl_ret) + '\n'
        mycontext['failure_messages'].append(error_str)
        return False
  
    elif not isinstance(model_ret, str) or not isinstance(impl_ret, str): 
      error_str = fnc_name + " action does not return correct types. The model should "
      error_str += "return a string and the impl should return a ModelObject. "
      error_str += str(model_ret) + ", " + str(impl_ret) + '\n'
      mycontext['failure_messages'].append(error_str)
      return False

    else:
      # All is well!
      return True
        
  elif fnc_name == "createthread":
    # TODO: Special circumstance, since createthread in the model returns a new 
    # threadid, it is different than the impl that returns nothing. This can be 
    # changed to match the impl now...I think?
    if model_ret is not None and not isinstance(model_ret, str):
      mycontext['failure_messages'].append("createthread model should return " + \
          "either None or a string, it was: " + str(model_ret))
      return False

    elif impl_ret is not None:
      mycontext['failure_messages'].append("createthread should return None" + \
          " it was: " + str(model_ret) + ", " + str(impl_ret))      
      return False
  
  elif fnc_name == "listfiles":
    if not isinstance(model_ret, list) or not isinstance(impl_ret, list):
      mycontext['failure_messages'].append("List files should return lists.")
      return False
    elif not set(model_ret).issubset(set(impl_ret)):
      # TODO: Special circumstance, for testing purposes we don't want to include the 
      #       entire file system in memory, only files we intend to touch.
      error_str = "Model list files should be a subset of impl list files."
      mycontext['failure_messages'].append(error_str)
      return False
    
  elif model_ret != impl_ret:
    log("**\nmodel:", model_ret, "\n**\nimpl:", impl_ret, '\n**\n')
    return False
  
  # All is well!
  return True




def _verify_model_impl_errors(fnc_name, repy_error, impl_error):
  if not isinstance(repy_error, type(impl_error)):
    error_str = "Model/Impl error's do not match: \n"
    error_str += str(repy_error) + ", " + str(impl_error)
    mycontext['failure_messages'].append(error_str)
    return False
  else:
    return True




def exec_and_verif_with_model(start_action_num):
  # Store model state prior to execution, just in case there is a failure.
  prestate = get_global_state_dict()

  # Grab the associated start/finish actions for this start action number.
  finish_action_num = mycontext['start_finish_map'][start_action_num]
  start_action = mycontext['trace_dict'][start_action_num]
  finish_action = mycontext['trace_dict'][finish_action_num]
  
  # Unpack the start/finish action tuples, discard the finish action model func, 
  # it is always None. FYI, the only reason it's there is to keep the lengths of 
  # actions constant.
  num1, fnc_name, start, threadname, obj_id, args_list, model_func = start_action
  num2, fnc_name2, finish, threadname2, obj_id2, return_val_tuple, _ = finish_action

  if DEBUG:
    log(start_action, '->\n')
    log('\t', finish_action, '\n')

  # Sanity Checks for start/finish action items
  assert(start == "start")
  assert(finish == "finish")
  assert(num1 == start_action_num)
  assert(num2 == finish_action_num)  
  assert(fnc_name == fnc_name2)
  assert(threadname == threadname2)
  assert(obj_id == obj_id2)

  # Before we can execute our action in the model we need to set our impl's 
  # value in the oracle, this way when the model asks the oracle for a hint 
  # it knows what the impl behavior.
  impl_ret, impl_error = return_val_tuple
  oracle_setter(impl_ret, impl_error)

  # Check to see if we are trying to call an object instance method. If so we 
  # need to retrieve the model id for our object and insert it into our 
  # arguments list before executing the call in the model.
  if fnc_name in OBJ_METHOD_CALLS_SET:
    # Copy args so we can modify them.
    model_args = list(args_list)
    # Get model object id from map.
    model_id = mycontext['translate_ids'][obj_id]
    model_args.insert(0, model_id)
  else:
    model_args = args_list
  
  # Finally, execute the action in the model.
  model_ret = repy_error = model_error = None
  try:
    model_ret = model_func(threadname, *model_args)
  except RepyException, repy_error:
    pass
  except InternalModelError, model_error:
    mycontext['failure_messages'].append(model_error)
    pass
  
  if DEBUG:
    log("\t", "model-return:", model_ret, ", model-raised:", repy_error, '\n')

  # If there was an internal model error then we are done.
  if model_error != None:
    put_global_state_dict(prestate)
    return None

  # If this function created an object, without error, we must store an id 
  # mapping from the original impl_obj to our new model_obj. That way later
  # method calls on this object will be associated with this model_obj.
  if fnc_name in OBJ_CREATE_CALLS_DICT and repy_error == None and impl_error == None:
    _assert_object(fnc_name, impl_ret)
    _get_and_store_obj_mapping(fnc_name, impl_ret, model_ret)
  
  # If there was an error, are they the same?
  if not _verify_model_impl_errors(fnc_name, repy_error, impl_error):
    put_global_state_dict(prestate)
    return None
  
  # Verify that the return values match or are otherwise acceptable.
  if not _verify_model_impl_values(fnc_name, model_ret, impl_ret):
    put_global_state_dict(prestate)
    return None

  # The model accepted the action, return the model's prestate to the caller 
  # indicating that we executed this action in the model successfully. The 
  # prestate is given to the caller just in case we must undo this action in 
  # the future.
  return prestate




# After each successful verification clear the following data structures.
def clear_verification_globals():
  temp_cond_dict = {}
  temp_trace_dict = {}
  for action_number in mycontext['pending_actions']:
    temp_cond_dict[action_number] = mycontext['condition_dict'][action_number]
    temp_trace_dict[action_number] = mycontext['trace_dict'][action_number]

  mycontext['condition_dict'] = {}
  mycontext['condition_dict'] = temp_cond_dict
  mycontext['start_finish_map'] = {}
  mycontext['trace_dict'] = {}
  mycontext['failure_messages'] = []
  mycontext['trace_dict'] = temp_trace_dict
  mycontext['finished_actions'] = []

  # Remove object ids that are no longer needed.
  while len(mycontext['dead_object_ids']) != 0:
    objid = mycontext['dead_object_ids'].pop()
    try:
      del mycontext['translate_ids'][objid]
    except KeyError:
      pass




def systolic_disambiguate_and_verify():
  sigma_list = mycontext['start_finish_map'].keys()  
  status_okay = create_tree(sigma_list, mycontext['condition_dict'])
  # write_str_to_log("*VERIFIED*\n")
  if status_okay:
    clear_verification_globals()
  return status_okay



# The main function that starts the systolic verification of the current in-memory 
# trace. In the normal CheckAPI case it is called from runtime_verification_core.
def check_and_possibly_verify(force=False):
  """
  NOTE: This call must be wrapped around a try/finally action_lock. If you 
    don't care about the trace length or any pending calls set force=True.
  """
  try:
    if force or (len(mycontext['trace_dict']) / 2 > SYSTOLIC_LEVELS and mycontext['special_pending_calls'] == 0):
      status_okay = systolic_disambiguate_and_verify()
      if not status_okay:
        for fail in mycontext['failure_messages']: 
          log(fail,'\n')
        for action_num in mycontext['trace_dict']: 
          log(mycontext['trace_dict'][action_num], '\n')
        raise ModelConformanceFailure("Could not find a valid serialization!")
  finally:
    empty_history()

